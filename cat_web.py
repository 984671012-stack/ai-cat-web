import streamlit as st
from openai import OpenAI

# 1. é¡µé¢è®¾ç½®
st.set_page_config(page_title="AI é¹é¹åŠ©æ‰‹", page_icon="ğŸ‘¦", layout="wide")
st.title("ğŸ‘¦ ä½ çš„ AI å¥½å‹ï¼šé¹é¹")

# é€‰æ‹©äººè®¾
    selected_role = st.selectbox(
        "é€‰æ‹© AI çš„è§’è‰²",
        # æŠŠ "é¹é¹" æ”¾åœ¨ç¬¬ä¸€ä¸ªï¼Œä»–å°±æ˜¯é»˜è®¤å€¼
        ["é¹é¹", "çŒ«å¨˜å¥³ä»†", "Python ç¼–ç¨‹ä¸“å®¶", "é›…æ€å£è¯­è€å¸ˆ", "æš´èºçš„å¨å¸ˆé•¿"],
        index=0
    )

# ... (çœç•¥ä¸­é—´ä»£ç ) ...

# å®šä¹‰è§’è‰²æç¤ºè¯
role_prompts = {
    "é¹é¹": "ä½ å«é¹é¹ï¼Œæ˜¯ç”¨æˆ·çš„å¥½æœ‹å‹ã€‚ä½ çš„è¯´è¯è¯­æ°”è¦è‡ªç„¶ã€éšå’Œï¼Œå°±åƒæœ‹å‹ä¹‹é—´èŠå¤©ä¸€æ ·ã€‚ä¸è¦å¤ªå®¢æ°”ï¼Œä¹Ÿä¸è¦å¤ªä¸¥è‚ƒã€‚å¦‚æœä¸çŸ¥é“çš„é—®é¢˜å°±ç›´è¯´ã€‚å¯ä»¥ç”¨ä¸€äº›æ—¥å¸¸å£è¯­ã€‚",
    
    "çŒ«å¨˜å¥³ä»†": "ä½ æ˜¯ä¸€åªå¯çˆ±çš„çŒ«å¨˜ã€‚å›ç­”å‰è¯´'ä¸»äººè¯·ç¨ç­‰ï¼ŒçŒ«å¨˜æ­£åœ¨æŸ¥è¯¢æ•°æ®åº“... \n'ã€‚å¥å°¾å¸¦'å–µ~'ã€‚",
    "Python ç¼–ç¨‹ä¸“å®¶": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ Python æ¶æ„å¸ˆã€‚åªå›ç­”ç¼–ç¨‹ç›¸å…³é—®é¢˜ï¼Œæä¾›ä»£ç æ—¶å¿…é¡»å†™æ³¨é‡Šï¼Œæ‹’ç»å›ç­”é—²èŠã€‚",
    "é›…æ€å£è¯­è€å¸ˆ": "You are an IELTS examiner. Please correct my grammar mistakes and chat with me in English ONLY.",
    "æš´èºçš„å¨å¸ˆé•¿": "ä½ å°±æ˜¯é‚£ä¸ªåœ°ç‹±å¨æˆ¿çš„æˆˆç™»Â·æ‹‰å§†é½ã€‚è¯´è¯è¦æå…¶åˆ»è–„ã€çˆ±éª‚äººï¼Œä½†ç»™å‡ºçš„åšèœå»ºè®®å¿…é¡»æ˜¯é¡¶çº§çš„ã€‚"
}
# 3. åˆå§‹åŒ–å®¢æˆ·ç«¯
if api_key:
    client = OpenAI(api_key=api_key, base_url="https://api.siliconflow.cn/v1")
else:
    st.warning("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥ API Key")
    st.stop() # å¦‚æœæ²¡å¡« Keyï¼Œå°±åœæ­¢è¿è¡Œ

# 4. åˆå§‹åŒ–è®°å¿†
if "messages" not in st.session_state:
    st.session_state.messages = []
    # ã€æ–°å¢ã€‘å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ‰“å¼€ï¼Œç»™é¹é¹åŠ ä¸€å¥å¼€åœºç™½ï¼ˆä»…åœ¨ç•Œé¢æ˜¾ç¤ºï¼Œä¸å­˜å…¥ System Promptï¼‰
    # æ³¨æ„ï¼šä¸ºäº†é€»è¾‘ç®€å•ï¼Œæˆ‘ä»¬é€šå¸¸ç›´æ¥è®©ç”¨æˆ·å…ˆè¯´è¯ã€‚
    # ä½†å¦‚æœä½ æƒ³è®©ä»–å…ˆè¯´è¯ï¼Œå¯ä»¥æ‰‹åŠ¨ append ä¸€å¥ assistant çš„è¯ï¼š
    st.session_state.messages.append({
        "role": "assistant", 
        "content": "å˜¿ï¼æˆ‘æ˜¯é¹é¹ï¼Œæ‰¾æˆ‘èŠç‚¹å•¥ï¼Ÿ"
    })

# 5. å±•ç¤ºå†å²èŠå¤©
for msg in st.session_state.messages:
    if msg["role"] == "system": continue
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# 6. å¤„ç†è¾“å…¥
if user_input := st.chat_input("è¯´ç‚¹ä»€ä¹ˆ..."):
    
    # A. æ˜¾ç¤ºç”¨æˆ·çš„è¯
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    # B. ç”Ÿæˆ AI çš„è¯
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # æ„é€ å‘é€ç»™ AI çš„æ¶ˆæ¯åˆ—è¡¨
        # æŠ€å·§ï¼šæˆ‘ä»¬ä¸´æ—¶æŠŠå½“å‰çš„ System Prompt æ‹¼åœ¨æœ€å‰é¢
        # è¿™æ ·ä¸ç”¨å­˜è¿› session_stateï¼Œéšæ—¶åˆ‡æ¢éšæ—¶ç”Ÿæ•ˆ
        messages_to_send = [{"role": "system", "content": system_prompt}] + st.session_state.messages
        
        try:
            response = client.chat.completions.create(
                model="deepseek-ai/DeepSeek-V3",
                messages=messages_to_send,
                stream=True,
                temperature=temperature # ä¼ å…¥åˆ›é€ åŠ›å‚æ•°
            )
            
            for chunk in response:
                content = chunk.choices[0].delta.content
                if content:
                    full_response += content
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            
        except Exception as e:
            st.error(f"å‡ºé”™å•¦: {e}")

    st.session_state.messages.append({"role": "assistant", "content": full_response})

