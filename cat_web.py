import streamlit as st
from openai import OpenAI

# 1. é¡µé¢è®¾ç½®
st.set_page_config(page_title="AI é¹é¹åŠ©æ‰‹", page_icon="ğŸ‘¦", layout="wide")
st.title("ğŸ‘¦ ä½ çš„ AI å¥½å‹ï¼šé¹é¹")

# ---ã€ä¿®å¤é‡ç‚¹ã€‘å®‰å…¨åˆå§‹åŒ–å˜é‡---
# å…ˆæŠŠ api_key è®¾ä¸ºç©ºï¼Œé˜²æ­¢åé¢æŠ¥ NameError
api_key = None 
# ---------------------------

# 2. ä¾§è¾¹æ é…ç½®åŒº (Sidebar)
with st.sidebar:
    st.header("âš™ï¸ é…ç½®é¢æ¿")
    
    # å°è¯•ä» Secrets è·å– Key
    if "SILICON_KEY" in st.secrets:
        api_key = st.secrets["SILICON_KEY"]
    else:
        # å¦‚æœæ²¡æœ‰ Secretsï¼Œæä¾›è¾“å…¥æ¡†
        api_key = st.text_input("è¯·è¾“å…¥ç¡…åŸºæµåŠ¨ API Key", type="password")
    
    # é€‰æ‹©äººè®¾
    selected_role = st.selectbox(
        "é€‰æ‹© AI çš„è§’è‰²",
        ["é¹é¹", "çŒ«å¨˜å¥³ä»†", "Python ç¼–ç¨‹ä¸“å®¶", "é›…æ€å£è¯­è€å¸ˆ", "æš´èºçš„å¨å¸ˆé•¿"],
        index=0
    )
    
    # è°ƒèŠ‚åˆ›é€ åŠ›
    temperature = st.slider("åˆ›é€ åŠ› (Temperature)", 0.0, 1.5, 0.7)
    
    # æ¸…ç©ºå¯¹è¯æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯è®°å¿†"):
        st.session_state.messages = []
        st.rerun()

# å®šä¹‰è§’è‰²æç¤ºè¯å­—å…¸
role_prompts = {
    "é¹é¹": "ä½ å«é¹é¹ï¼Œæ˜¯ç”¨æˆ·çš„å¥½æœ‹å‹ã€‚ä½ çš„è¯´è¯è¯­æ°”è¦è‡ªç„¶ã€éšå’Œï¼Œå°±åƒæœ‹å‹ä¹‹é—´èŠå¤©ä¸€æ ·ã€‚ä¸è¦å¤ªå®¢æ°”ï¼Œä¹Ÿä¸è¦å¤ªä¸¥è‚ƒã€‚å¦‚æœä¸çŸ¥é“çš„é—®é¢˜å°±ç›´è¯´ã€‚å¯ä»¥ç”¨ä¸€äº›æ—¥å¸¸å£è¯­ã€‚",
    "çŒ«å¨˜å¥³ä»†": "ä½ æ˜¯ä¸€åªå¯çˆ±çš„çŒ«å¨˜ã€‚å›ç­”å‰è¯´'ä¸»äººè¯·ç¨ç­‰ï¼ŒçŒ«å¨˜æ­£åœ¨æŸ¥è¯¢æ•°æ®åº“... \n'ã€‚å¥å°¾å¸¦'å–µ~'ã€‚",
    "Python ç¼–ç¨‹ä¸“å®¶": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ Python æ¶æ„å¸ˆã€‚åªå›ç­”ç¼–ç¨‹ç›¸å…³é—®é¢˜ï¼Œæä¾›ä»£ç æ—¶å¿…é¡»å†™æ³¨é‡Šï¼Œæ‹’ç»å›ç­”é—²èŠã€‚",
    "é›…æ€å£è¯­è€å¸ˆ": "You are an IELTS examiner. Please correct my grammar mistakes and chat with me in English ONLY.",
    "æš´èºçš„å¨å¸ˆé•¿": "ä½ å°±æ˜¯é‚£ä¸ªåœ°ç‹±å¨æˆ¿çš„æˆˆç™»Â·æ‹‰å§†é½ã€‚è¯´è¯è¦æå…¶åˆ»è–„ã€çˆ±éª‚äººï¼Œä½†ç»™å‡ºçš„åšèœå»ºè®®å¿…é¡»æ˜¯é¡¶çº§çš„ã€‚"
}

# 3. åˆå§‹åŒ–å®¢æˆ·ç«¯
# è¿™é‡Œå°±æ˜¯æŠ¥é”™çš„åœ°æ–¹ï¼Œç°åœ¨ä¸Šé¢å®šä¹‰è¿‡äº†ï¼Œå°±ä¸ä¼šæŠ¥é”™äº†
if api_key:
    client = OpenAI(api_key=api_key, base_url="https://api.siliconflow.cn/v1")
else:
    # å¦‚æœæ—¢æ²¡æœ‰ secrets ä¹Ÿæ²¡å¡«è¾“å…¥æ¡†
    st.warning("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥ API Keyï¼Œæˆ–è€…åœ¨ Secrets ä¸­é…ç½®")
    st.stop() # åœæ­¢è¿è¡Œï¼Œé˜²æ­¢åç»­æŠ¥é”™

# 4. åˆå§‹åŒ–è®°å¿†
if "messages" not in st.session_state:
    st.session_state.messages = []
    # ç»™é¹é¹åŠ ä¸ªå¼€åœºç™½
    st.session_state.messages.append({
        "role": "assistant", 
        "content": "å˜¿ï¼æˆ‘æ˜¯é¹é¹ï¼Œæ‰¾æˆ‘èŠç‚¹å•¥ï¼Ÿ"
    })

# è·å–å½“å‰è§’è‰²çš„ System Prompt
system_prompt = role_prompts[selected_role]

# 5. å±•ç¤ºå†å²èŠå¤©
for msg in st.session_state.messages:
    if msg["role"] == "system": continue
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# 6. å¤„ç†è¾“å…¥
if user_input := st.chat_input("è¯´ç‚¹ä»€ä¹ˆ..."):
    
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # æ„é€ å‘é€ç»™ AI çš„æ¶ˆæ¯åˆ—è¡¨
        messages_to_send = [{"role": "system", "content": system_prompt}] + st.session_state.messages
        
        try:
            response = client.chat.completions.create(
                model="deepseek-ai/DeepSeek-V3",
                messages=messages_to_send,
                stream=True,
                temperature=temperature
            )
            
            for chunk in response:
                content = chunk.choices[0].delta.content
                if content:
                    full_response += content
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            
        except Exception as e:
            st.error(f"å‡ºé”™å•¦: {e}")

    st.session_state.messages.append({"role": "assistant", "content": full_response})



